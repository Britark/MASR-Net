import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from losses import *
import torch.optim as optim
from tqdm import tqdm
import time
import numpy as np
import math
from datetime import datetime
import argparse
import kornia.metrics as K
import shutil
import warnings

# æŠ‘åˆ¶torch.cuda.amp.autocastçš„FutureWarning
warnings.filterwarnings('ignore', category=FutureWarning, message='.*torch.cuda.amp.autocast.*')

# å…¼å®¹ä¸åŒPyTorchç‰ˆæœ¬çš„æ··åˆç²¾åº¦å¯¼å…¥
try:
    from torch.amp import autocast, GradScaler

    AMP_AVAILABLE = True
    USE_NEW_AMP = True
except ImportError:
    try:
        from torch.cuda.amp import autocast, GradScaler

        AMP_AVAILABLE = True
        USE_NEW_AMP = False
    except ImportError:
        AMP_AVAILABLE = False
        USE_NEW_AMP = False
        print("è­¦å‘Šï¼šæ— æ³•å¯¼å…¥æ··åˆç²¾åº¦è®­ç»ƒæ¨¡å—ï¼Œå°†ç¦ç”¨AMP")

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data_loader import get_data_loaders
from models import Model
from config import default_config

# Optunaé›†æˆ
try:
    import optuna
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False
    print("è­¦å‘Šï¼šOptunaæœªå®‰è£…ï¼Œå°†è·³è¿‡è¶…å‚æ•°ä¼˜åŒ–åŠŸèƒ½")


def check_gradients(model, batch_idx, epoch):
    """
    æ£€æŸ¥æ¨¡å‹æ¢¯åº¦çŠ¶æ€ï¼Œä¸“æ³¨æ˜¾ç¤ºé›¶æ¢¯åº¦å‚æ•°
    Args:
        model: è®­ç»ƒæ¨¡å‹
        batch_idx: å½“å‰batchç´¢å¼•
        epoch: å½“å‰epoch
    """

    total_params = 0
    zero_grad_params = 0
    nan_grad_params = 0
    normal_grad_params = 0
    
    # è®°å½•é›¶æ¢¯åº¦å‚æ•°
    zero_grad_details = {}

    for name, param in model.named_parameters():
        if param.grad is not None:
            grad = param.grad
            grad_norm = torch.norm(grad).item()

            # æ£€æŸ¥æ¢¯åº¦çŠ¶æ€
            has_nan = torch.isnan(grad).any().item()
            has_inf = torch.isinf(grad).any().item()
            is_zero = (grad_norm < 1e-10)

            if has_nan:
                nan_grad_params += 1
            elif is_zero:
                zero_grad_params += 1
                # è®°å½•é›¶æ¢¯åº¦å‚æ•°è¯¦æƒ…
                module_name = name.split('.')[0]
                if module_name not in zero_grad_details:
                    zero_grad_details[module_name] = []
                zero_grad_details[module_name].append(name)
            else:
                normal_grad_params += 1

            total_params += 1

    print(f"\nğŸ“Š æ¢¯åº¦ç»Ÿè®¡ [Epoch {epoch}, Batch {batch_idx}]:")
    print(f"  æ€»å‚æ•°: {total_params}, æ­£å¸¸: {normal_grad_params} ({normal_grad_params / total_params * 100:.1f}%), é›¶æ¢¯åº¦: {zero_grad_params} ({zero_grad_params / total_params * 100:.1f}%), NaN: {nan_grad_params} ({nan_grad_params / total_params * 100:.1f}%)")
    
    # åªæ˜¾ç¤ºæœ‰é›¶æ¢¯åº¦çš„æ¨¡å—å’Œå…·ä½“å‚æ•°
    if zero_grad_details:
        print(f"\nğŸ” é›¶æ¢¯åº¦å‚æ•°è¯¦æƒ…:")
        for module_name, param_names in zero_grad_details.items():
            print(f"  ğŸ“¦ {module_name} ({len(param_names)}ä¸ªé›¶æ¢¯åº¦å‚æ•°):")
            for param_name in param_names:
                print(f"    - {param_name}")
        print("=" * 80)
    else:
        print("âœ… æ‰€æœ‰å‚æ•°éƒ½æœ‰æ­£å¸¸æ¢¯åº¦æµï¼")
        print("=" * 80)


def calculate_psnr(img1, img2):
    """ä½¿ç”¨Korniaè®¡ç®—PSNR"""
    img1 = torch.clamp(img1, 0, 1)
    img2 = torch.clamp(img2, 0, 1)
    return K.psnr(img1, img2, max_val=1.0).mean().item()


def calculate_ssim(img1, img2):
    """ä½¿ç”¨Korniaè®¡ç®—SSIM"""
    img1 = torch.clamp(img1, 0, 1)
    img2 = torch.clamp(img2, 0, 1)
    return K.ssim(img1, img2, window_size=11, max_val=1.0).mean().item()


def suggest_hyperparameters(trial):
    """å»ºè®®è¶…å‚æ•°ï¼ˆåŸºäºOptunaé‡è¦æ€§åˆ†æç»“æœä¼˜åŒ–ï¼‰"""
    return {
        # === Tier 1: æœ€é«˜é‡è¦æ€§å‚æ•°ï¼ˆç²¾ç»†è°ƒæ•´ï¼‰===
        'learning_rate': trial.suggest_float('learning_rate', 6.5e-5, 7.8e-5),  # é‡è¦æ€§0.25-0.26
        'psnr_weight': trial.suggest_float('psnr_weight', 0.08, 0.12),          # é‡è¦æ€§0.26-0.28
        
        # === Tier 2: é«˜é‡è¦æ€§å‚æ•°ï¼ˆé€‚åº¦è°ƒæ•´ï¼‰===
        'lab_color_weight': trial.suggest_float('lab_color_weight', 0.006, 0.015), # é‡è¦æ€§0.15-0.28
        'reconstruction_weight': trial.suggest_float('reconstruction_weight', 1.48, 1.58), # é‡è¦æ€§0.07-0.33 (PED ANOVAæœ€é«˜)
        
        # === å›ºå®šå‚æ•°ï¼ˆåŸºäºæœ€ä½³è¯•éªŒ#23çš„å€¼ï¼Œä½é‡è¦æ€§ï¼‰===
        'perceptual_weight': 0.232,    # é‡è¦æ€§0.02-0.07ï¼Œå›ºå®šä¸ºæœ€ä½³å€¼
        'ssim_weight': 0.126,          # é‡è¦æ€§0.01-0.05ï¼Œå›ºå®šä¸ºæœ€ä½³å€¼  
        'auxiliary_weight': 0.107,     # é‡è¦æ€§0.02-0.11ï¼Œå›ºå®šä¸ºæœ€ä½³å€¼
    }


def create_config_with_weights(loss_weights):
    """åˆ›å»ºåŒ…å«æŒ‡å®šæŸå¤±æƒé‡çš„é…ç½®ï¼Œå¹¶å¢åŠ éªŒè¯"""
    config = default_config()
    config['loss_weights'] = loss_weights
    
    # === æ–°å¢ï¼šè¯¦ç»†æ—¥å¿— ===
    print(f"ğŸ“‹ åˆ›å»ºé…ç½®ï¼ŒæŸå¤±æƒé‡:")
    total_weight = sum(loss_weights.values())
    for key, value in loss_weights.items():
        percentage = (value / total_weight) * 100
        print(f"  {key}: {value:.6f} ({percentage:.1f}%)")
    print(f"  æ€»æƒé‡: {total_weight:.6f}")
    
    return config


def train_and_evaluate_for_optuna(config, data_loaders, device, learning_rate, max_epochs=8):
    """ä¸ºOptunaä¼˜åŒ–è®¾è®¡çš„è®­ç»ƒå’Œè¯„ä¼°å‡½æ•°"""
    train_loader, val_loader = data_loaders
    
    # === æ·»åŠ éšæœºç§å­æ§åˆ¶ç¡®ä¿å¯é‡ç°æ€§ ===
    import random
    import numpy as np
    
    seed = 3407  # å›ºå®šç§å­ç¡®ä¿å¯é‡ç°æ€§
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    print(f"ğŸ² è®¾ç½®éšæœºç§å­: {seed}")
    
    # === éªŒè¯ä¼ å…¥çš„æŸå¤±æƒé‡é…ç½® ===
    print(f"\nğŸ” éªŒè¯ä¼ å…¥çš„æŸå¤±æƒé‡é…ç½®:")
    loss_weights = config.get('loss_weights', {})
    total_weight = sum(loss_weights.values())
    
    for key, value in loss_weights.items():
        percentage = (value / total_weight) * 100 if total_weight > 0 else 0
        print(f"  {key}: {value:.6f} ({percentage:.1f}%)")
    print(f"  æ€»æƒé‡: {total_weight:.6f}")
    
    # éªŒè¯å¿…è¦å‚æ•°æ˜¯å¦å­˜åœ¨
    required_params = ['reconstruction_weight', 'auxiliary_weight', 'psnr_weight', 
                       'ssim_weight', 'lab_color_weight', 'perceptual_weight']
    missing_params = [param for param in required_params if param not in loss_weights]
    if missing_params:
        print(f"âŒ è­¦å‘Š: ç¼ºå¤±å‚æ•° {missing_params}, å°†ä½¿ç”¨é»˜è®¤å€¼")
        return float('inf')  # å¦‚æœå‚æ•°ä¼ é€’å¤±è´¥ï¼Œç›´æ¥è¿”å›æœ€å·®åˆ†æ•°
    
    # CUDAçŠ¶æ€æ£€æŸ¥å’Œæ¸…ç†ï¼ˆåªåœ¨å¼€å§‹æ—¶è¿›è¡Œï¼‰
    try:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
    except:
        print("âš ï¸ CUDAæ¸…ç†å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ...")
        pass
    
    # åˆ›å»ºæ¨¡å‹
    try:
        model = Model(config).to(device)
    except Exception as e:
        print(f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return float('inf')
    
    # åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨Optunaå»ºè®®çš„å­¦ä¹ ç‡ï¼‰
    optimizer = optim.AdamW(
        model.parameters(),
        lr=learning_rate,  # ä½¿ç”¨Optunaå»ºè®®çš„å­¦ä¹ ç‡
        weight_decay=1e-4,
        betas=(0.9, 0.999),
        eps=1e-8
    )
    
    # æ··åˆç²¾åº¦è®¾ç½®
    use_amp = torch.cuda.is_available() and AMP_AVAILABLE
    scaler = GradScaler() if use_amp else None
    
    best_val_psnr = 0.0
    patience = 0
    max_patience = 999  # åŸºæœ¬ä¸ä¼šè§¦å‘æ—©åœ
    
    for epoch in range(1, max_epochs + 1):
        # è®­ç»ƒä¸€ä¸ªepoch
        model.train()
        total_loss = 0
        num_batches = 0
        
        # é™åˆ¶æ¯ä¸ªepochçš„batchæ•°é‡ä»¥åŠ é€Ÿï¼ˆå¢åŠ åˆ°100ä»¥è·å¾—æ›´å‡†ç¡®çš„è¯„ä¼°ï¼‰
        max_train_batches = min(100, len(train_loader))
        
        for batch_idx, batch_data in enumerate(train_loader):
            if batch_idx >= max_train_batches:
                break
                
            inputs = batch_data['input'].to(device, non_blocking=True)
            targets = batch_data['target'].to(device, non_blocking=True)
            
            optimizer.zero_grad(set_to_none=True)
            
            try:
                if use_amp:
                    if USE_NEW_AMP:
                        with autocast('cuda'):
                            enhanced_images, loss, reconstruction_loss = model(inputs, targets)
                    else:
                        with autocast():
                            enhanced_images, loss, reconstruction_loss = model(inputs, targets)
                    scaler.scale(loss).backward()
                    scaler.step(optimizer)
                    scaler.update()
                else:
                    enhanced_images, loss, reconstruction_loss = model(inputs, targets)
                    loss.backward()
                    optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
                
            except RuntimeError as e:
                if "CUDA" in str(e) or "index out of bounds" in str(e) or "device-side assert" in str(e):
                    print(f"ğŸš« CUDAé”™è¯¯ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡: {e}")
                    # ä¸è°ƒç”¨torch.cuda.empty_cache()ï¼Œé¿å…è¿›ä¸€æ­¥CUDAé”™è¯¯
                    print(f"ğŸš« å‘ç°é—®é¢˜å›¾ç‰‡ï¼è·³è¿‡batch {batch_idx} (è¿™æ˜¯æ­£å¸¸çš„ï¼Œçº¦1%æ¦‚ç‡)")
                    # è®°å½•é—®é¢˜batchä¿¡æ¯åˆ°æ–‡ä»¶
                    with open('problematic_batches.log', 'a') as f:
                        f.write(f"Epoch {epoch}, Batch {batch_idx}: CUDA error\n")
                    
                    # é‡ç½®CUDAä¸Šä¸‹æ–‡
                    try:
                        torch.cuda.empty_cache()
                        torch.cuda.synchronize()
                    except:
                        pass
                    continue
                else:
                    print(f"å…¶ä»–è¿è¡Œæ—¶é”™è¯¯: {e}")
                    continue
            except Exception as e:
                print(f"è®­ç»ƒæ‰¹æ¬¡å¤±è´¥: {e}")
                continue
        
        if num_batches == 0:
            return float('inf')  # è®­ç»ƒå¤±è´¥
            
        avg_train_loss = total_loss / num_batches
        
        # éªŒè¯
        val_psnr = validate_for_optuna(model, val_loader, device, use_amp)
        
        print(f"Epoch {epoch}: Train Loss: {avg_train_loss:.4f}, Val PSNR: {val_psnr:.2f}")
        
        # æ—©åœæ£€æŸ¥
        if val_psnr > best_val_psnr:
            best_val_psnr = val_psnr
            patience = 0
        else:
            patience += 1
            if patience >= max_patience:
                print(f"æ—©åœäºepoch {epoch}")
                break
    
    return -best_val_psnr  # è¿”å›è´Ÿå€¼å› ä¸ºOptunaè¦æœ€å°åŒ–


def validate_for_optuna(model, val_loader, device, use_amp=False):
    """ä¸ºOptunaä¼˜åŒ–è®¾è®¡çš„éªŒè¯å‡½æ•°"""
    model.eval()
    total_psnr = 0
    num_batches = 0
    
    # é™åˆ¶éªŒè¯batchæ•°é‡
    max_val_batches = min(30, len(val_loader))
    
    with torch.no_grad():
        for batch_idx, batch_data in enumerate(val_loader):
            if batch_idx >= max_val_batches:
                break
                
            inputs = batch_data['input'].to(device, non_blocking=True)
            targets = batch_data['target'].to(device, non_blocking=True)
            
            try:
                # éªŒè¯æ—¶éœ€è¦å°†æ¨¡å‹è®¾ä¸ºè®­ç»ƒæ¨¡å¼ä»¥è·å–æŸå¤±è®¡ç®—ï¼Œä½†ä¸æ›´æ–°æ¢¯åº¦
                model.train()  # ä¸´æ—¶è®¾ä¸ºè®­ç»ƒæ¨¡å¼ä»¥è·å–æŸå¤±
                if use_amp:
                    if USE_NEW_AMP:
                        with autocast('cuda'):
                            enhanced_images, total_loss, reconstruction_loss = model(inputs, targets)
                    else:
                        with autocast():
                            enhanced_images, total_loss, reconstruction_loss = model(inputs, targets)
                else:
                    enhanced_images, total_loss, reconstruction_loss = model(inputs, targets)
                model.eval()  # æ¢å¤è¯„ä¼°æ¨¡å¼
                
                # è®¡ç®—PSNRç”¨äºä¼˜åŒ–ç›®æ ‡
                psnr_value = calculate_psnr(enhanced_images, targets)
                total_psnr += psnr_value
                num_batches += 1
                
            except RuntimeError as e:
                if "CUDA" in str(e) or "index out of bounds" in str(e) or "device-side assert" in str(e):
                    print(f"ğŸš« CUDAé”™è¯¯ï¼Œè·³è¿‡éªŒè¯æ‰¹æ¬¡: {e}")
                    # ä¸è°ƒç”¨torch.cuda.empty_cache()ï¼Œé¿å…è¿›ä¸€æ­¥CUDAé”™è¯¯
                    continue
                else:
                    print(f"å…¶ä»–éªŒè¯é”™è¯¯: {e}")
                    continue
            except Exception as e:
                print(f"éªŒè¯æ‰¹æ¬¡å¤±è´¥: {e}")
                continue
    
    return total_psnr / max(num_batches, 1)


def optuna_objective(trial, data_loaders, device, args):
    """Optunaç›®æ ‡å‡½æ•°"""
    if not OPTUNA_AVAILABLE:
        raise RuntimeError("Optunaæœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–")
    
    # æ¯ä¸ªtrialå¼€å§‹å‰å°è¯•é‡ç½®CUDAçŠ¶æ€
    reset_cuda_context()
    
    # å»ºè®®è¶…å‚æ•°ï¼ˆåŒ…æ‹¬æŸå¤±æƒé‡å’Œå­¦ä¹ ç‡ï¼‰
    hyperparams = suggest_hyperparameters(trial)
    
    # åˆ†ç¦»æŸå¤±æƒé‡å’Œå­¦ä¹ ç‡
    learning_rate = hyperparams.pop('learning_rate')
    loss_weights = hyperparams
    
    # åˆ›å»ºé…ç½®
    config = create_config_with_weights(loss_weights)
    
    # æ‰“å°å½“å‰è¯•éªŒçš„è¶…å‚æ•°
    print(f"\nTrial {trial.number} è¶…å‚æ•°:")
    print(f"  learning_rate: {learning_rate:.6f}")
    for key, value in loss_weights.items():
        print(f"  {key}: {value:.4f}")
    
    # è®­ç»ƒå’Œè¯„ä¼°
    try:
        score = train_and_evaluate_for_optuna(config, data_loaders, device, learning_rate, max_epochs=args.optuna_epochs)
        
        # æ£€æŸ¥scoreæ˜¯å¦æœ‰æ•ˆ
        if score == float('inf') or score != score:  # score != score æ£€æŸ¥NaN
            print(f"Trial {trial.number} å¤±è´¥: æ— æ•ˆå¾—åˆ† {score}")
            return float('inf')
            
        print(f"Trial {trial.number} å®Œæˆï¼Œå¾—åˆ†: {score:.4f}")
        
        # å‘trialæŠ¥å‘Šä¸­é—´ç»“æœ
        trial.report(score, args.optuna_epochs)
        
        return score
    except RuntimeError as e:
        if "CUDA" in str(e) or "index out of bounds" in str(e) or "device-side assert" in str(e):
            print(f"ğŸš« Trial {trial.number} CUDAé”™è¯¯ï¼Œè·³è¿‡: {e}")
            # ä¸è°ƒç”¨torch.cuda.empty_cache()ï¼Œé¿å…è¿›ä¸€æ­¥CUDAé”™è¯¯
            return float('inf')  # è¿”å›æœ€å·®åˆ†æ•°ï¼Œè®©Optunaè·³è¿‡
        else:
            print(f"Trial {trial.number} è¿è¡Œæ—¶é”™è¯¯: {e}")
            return float('inf')
    except Exception as e:
        print(f"Trial {trial.number} å…¶ä»–é”™è¯¯: {e}")
        return float('inf')


def reset_cuda_context():
    """é‡ç½®CUDAä¸Šä¸‹æ–‡ï¼Œç”¨äºä»ä¸¥é‡CUDAé”™è¯¯ä¸­æ¢å¤"""
    try:
        if torch.cuda.is_available():
            # å°è¯•é‡ç½®CUDAä¸Šä¸‹æ–‡
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
            torch.cuda.synchronize()
    except:
        try:
            # å¦‚æœæ­£å¸¸é‡ç½®å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶é‡ç½®
            import subprocess
            result = subprocess.run(['nvidia-smi', '--gpu-reset'], 
                                   capture_output=True, text=True)
            print("ğŸ”„ æ‰§è¡Œäº†GPUé‡ç½®")
        except:
            print("âš ï¸ æ— æ³•é‡ç½®CUDAä¸Šä¸‹æ–‡ï¼Œç»§ç»­æ‰§è¡Œ...")
            pass


def run_diagnostic_test():
    """è¿è¡Œè¯Šæ–­æµ‹è¯•ï¼ŒéªŒè¯å‚æ•°ä¼ é€’å’Œæ¨¡å‹é…ç½®"""
    print("ğŸ”§ å¼€å§‹è¯Šæ–­æµ‹è¯•...")
    
    # åˆ›å»ºå·²çŸ¥çš„æƒé‡é…ç½®
    test_weights = {
        'reconstruction_weight': 1.5,
        'auxiliary_weight': 0.4,
        'psnr_weight': 0.3,
        'ssim_weight': 0.2,
        'lab_color_weight': 0.05,
        'perceptual_weight': 0.15
    }
    
    print("ğŸ“‹ æµ‹è¯•æƒé‡é…ç½®:")
    for key, value in test_weights.items():
        print(f"  {key}: {value}")
    
    # åˆ›å»ºé…ç½®å¹¶æ¨¡å‹
    config = create_config_with_weights(test_weights)
    try:
        model = Model(config)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # éªŒè¯æ¨¡å‹ä¸­çš„æƒé‡æ˜¯å¦æ­£ç¡®è®¾ç½®
    print("\nğŸ” æ¨¡å‹æƒé‡éªŒè¯:")
    print(f"  reconstruction_weight: {model.reconstruction_weight}")
    print(f"  auxiliary_weight: {model.auxiliary_weight}")
    print(f"  perceptual_weight: {model.perceptual_weight}")
    print(f"  psnr_weight: {model.psnr_weight}")
    print(f"  ssim_weight: {model.ssim_weight}")
    print(f"  lab_color_weight: {model.lab_color_weight}")
    
    # æ£€æŸ¥å±æ€§æ˜¯å¦å­˜åœ¨
    required_attrs = ['reconstruction_weight', 'auxiliary_weight', 'perceptual_weight', 
                      'psnr_weight', 'ssim_weight', 'lab_color_weight']
    
    missing_attrs = []
    for attr in required_attrs:
        if not hasattr(model, attr):
            missing_attrs.append(attr)
    
    if missing_attrs:
        print(f"âŒ ç¼ºå¤±å±æ€§: {missing_attrs}")
        return False
    else:
        print("âœ… æ‰€æœ‰æƒé‡å±æ€§æ­£ç¡®è®¾ç½®")
        return True


def run_optuna_optimization(args):
    """è¿è¡ŒOptunaè¶…å‚æ•°ä¼˜åŒ–"""
    if not OPTUNA_AVAILABLE:
        print("é”™è¯¯ï¼šOptunaæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install optuna")
        return
    
    print("ğŸš€ å¼€å§‹Optunaè¶…å‚æ•°ä¼˜åŒ–...")
    print(f"è¯•éªŒæ¬¡æ•°: {args.optuna_trials}")
    print(f"æ¯ä¸ªè¯•éªŒè®­ç»ƒè½®æ•°: {args.optuna_epochs}")
    print(f"ç ”ç©¶åç§°: {args.optuna_study_name}")
    print(f"å­˜å‚¨ä½ç½®: {args.optuna_storage}")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®
    root_dir = os.path.expanduser(args.data_dir)
    train_loader, val_loader, _ = get_data_loaders(
        root_dir=root_dir,
        batch_size=args.batch_size,
        eval_batch_size=4,  # æ›´å°çš„éªŒè¯batch
        num_workers=args.num_workers
    )
    
    data_loaders = (train_loader, val_loader)
    
    # åˆ›å»ºå­˜å‚¨ç›®å½•
    storage_dir = os.path.dirname(args.optuna_storage.replace('sqlite:///', ''))
    if storage_dir:
        os.makedirs(storage_dir, exist_ok=True)
    
    # åˆ›å»ºæˆ–åŠ è½½ç ”ç©¶
    try:
        study = optuna.create_study(
            study_name=args.optuna_study_name,
            storage=args.optuna_storage,
            load_if_exists=True,
            direction="minimize",  # æœ€å°åŒ–æŸå¤±(è´ŸPSNR)
            pruner=optuna.pruners.HyperbandPruner(
                min_resource=3,          # æœ€å°‘è®­ç»ƒ3ä¸ªepoch
                max_resource=args.optuna_epochs,  # æœ€å¤šè®­ç»ƒæŒ‡å®šepochs
                reduction_factor=3       # å®˜æ–¹æ¨èçš„å‡å°‘å› å­
            )
        )
        print(f"âœ… ç ”ç©¶ '{args.optuna_study_name}' åˆ›å»º/åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åˆ›å»ºç ”ç©¶å¤±è´¥: {e}")
        return
    
    # å®šä¹‰ä¼˜åŒ–ç›®æ ‡çš„åŒ…è£…å‡½æ•°
    def objective_wrapper(trial):
        return optuna_objective(trial, data_loaders, device, args)
    
    # å¼€å§‹ä¼˜åŒ–
    try:
        print(f"\nğŸ” å¼€å§‹ä¼˜åŒ–ï¼Œç›®æ ‡: æœ€å¤§åŒ–éªŒè¯PSNR...")
        study.optimize(objective_wrapper, n_trials=args.optuna_trials)
        
        # æ˜¾ç¤ºç»“æœ
        print("\nğŸ‰ ä¼˜åŒ–å®Œæˆï¼")
        print(f"æœ€ä½³éªŒè¯PSNR: {-study.best_value:.2f}")
        print("æœ€ä½³æŸå¤±æƒé‡:")
        for key, value in study.best_params.items():
            print(f"  {key}: {value:.4f}")
        
        # ä¿å­˜æœ€ä½³å‚æ•°åˆ°æ–‡ä»¶
        best_config = create_config_with_weights(study.best_params)
        import json
        with open(f'best_loss_weights_{args.optuna_study_name}.json', 'w') as f:
            json.dump(study.best_params, f, indent=2)
        print(f"\nğŸ’¾ æœ€ä½³å‚æ•°å·²ä¿å­˜åˆ°: best_loss_weights_{args.optuna_study_name}.json")
        
        # æç¤ºå¦‚ä½•æŸ¥çœ‹dashboard
        print(f"\nğŸ“Š æŸ¥çœ‹ä¼˜åŒ–ç»“æœ:")
        print(f"1. å¯åŠ¨dashboard: optuna-dashboard {args.optuna_storage}")
        print(f"2. é€šè¿‡SSHéš§é“è®¿é—®: ssh -L 8080:localhost:8080 ç”¨æˆ·å@æœåŠ¡å™¨IP")
        print(f"3. æµè§ˆå™¨æ‰“å¼€: http://localhost:8080")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ä¼˜åŒ–è¢«ç”¨æˆ·ä¸­æ–­")
        if study.trials:
            print(f"å·²å®Œæˆ {len(study.trials)} ä¸ªè¯•éªŒ")
            if study.best_trial:
                print(f"å½“å‰æœ€ä½³PSNR: {-study.best_value:.2f}")
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def warmup_cosine_schedule(optimizer, epoch, warmup_epochs, total_epochs, min_lr_factor=0.01, steepness=2.0,acceleration_factor=1.0):
    """
    å®ç°warmup + ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦çš„å‡½æ•°ï¼ˆå¢åŠ é™¡å³­åº¦å‚æ•°ï¼‰

    Args:
        optimizer: ä¼˜åŒ–å™¨
        epoch: å½“å‰epoch
        warmup_epochs: é¢„çƒ­é˜¶æ®µçš„è½®æ•°
        total_epochs: æ€»è®­ç»ƒè½®æ•°
        min_lr_factor: æœ€å°å­¦ä¹ ç‡æ˜¯åˆå§‹å­¦ä¹ ç‡çš„å€æ•°
        steepness: é™¡å³­åº¦å‚æ•°ï¼Œè¶Šå¤§è¡°å‡è¶Šå¿«
    """
    # ä¿å­˜åŸºç¡€å­¦ä¹ ç‡
    if not hasattr(warmup_cosine_schedule, 'base_lrs'):
        warmup_cosine_schedule.base_lrs = [group['lr'] for group in optimizer.param_groups]

    # é¢„çƒ­é˜¶æ®µ
    if epoch < warmup_epochs:
        # çº¿æ€§é¢„çƒ­
        factor = float(epoch) / float(max(1, warmup_epochs))
        for i, group in enumerate(optimizer.param_groups):
            group['lr'] = warmup_cosine_schedule.base_lrs[i] * factor
    # ä½™å¼¦é€€ç«é˜¶æ®µ
    else:
        # è®¡ç®—ä½™å¼¦é€€ç«çš„è¿›åº¦
        progress = float(epoch - warmup_epochs) * acceleration_factor / float(max(1, total_epochs - warmup_epochs))
        # æ·»åŠ steepnesså‚æ•°è®©è¡°å‡æ›´é™¡å³­
        cosine_factor = math.cos(math.pi * progress)
        factor = max(min_lr_factor,
                     0.5 * (1.0 + math.pow(abs(cosine_factor), steepness) * (1 if cosine_factor >= 0 else -1)))
        for i, group in enumerate(optimizer.param_groups):
            group['lr'] = warmup_cosine_schedule.base_lrs[i] * factor


def train_one_epoch(model, train_loader, optimizer, device, epoch, scaler=None, use_amp=False, check_grad_every=1):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    total_reconstruction_loss = 0
    total_psnr = 0
    total_ssim = 0


    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f"Epoch {epoch}", ncols=0, leave=True)

    for batch_idx, batch_data in progress_bar:
        inputs = batch_data['input'].to(device, non_blocking=True)
        targets = batch_data['target'].to(device, non_blocking=True)

        optimizer.zero_grad(set_to_none=True)

        if use_amp:
            if USE_NEW_AMP:
                with autocast('cuda'):
                    enhanced_images, loss, reconstruction_loss = model(inputs, targets)
            else:
                with autocast():
                    enhanced_images, loss, reconstruction_loss = model(inputs, targets)

            scaler.scale(loss).backward()

            # ========== æ¯ä¸ªbatchéƒ½æ£€æŸ¥æ¢¯åº¦ ==========
            # éœ€è¦å…ˆunscaleæ¥æ£€æŸ¥çœŸå®æ¢¯åº¦
            scaler.unscale_(optimizer)
            check_gradients(model, batch_idx, epoch)

            # æ¢¯åº¦è£å‰ªå‰æ£€æŸ¥æ˜¯å¦éœ€è¦è£å‰ª
            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=float('inf'))
            if grad_norm > 1.0:
                print(f"ğŸ”§ [Epoch {epoch}, Batch {batch_idx}] æ¢¯åº¦èŒƒæ•°è¿‡å¤§: {grad_norm:.6f} > 1.0, æ‰§è¡Œæ¢¯åº¦è£å‰ª!")
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            scaler.step(optimizer)
            scaler.update()
        else:
            enhanced_images, loss, reconstruction_loss = model(inputs, targets)
            loss.backward()

            # ========== æ¯ä¸ªbatchéƒ½æ£€æŸ¥æ¢¯åº¦ ==========
            check_gradients(model, batch_idx, epoch)

            # æ¢¯åº¦è£å‰ªå‰æ£€æŸ¥æ˜¯å¦éœ€è¦è£å‰ª
            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=float('inf'))
            if grad_norm > 1.0:
                print(f"ğŸ”§ [Epoch {epoch}, Batch {batch_idx}] æ¢¯åº¦èŒƒæ•°è¿‡å¤§: {grad_norm:.6f} > 1.0, æ‰§è¡Œæ¢¯åº¦è£å‰ª!")
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            else:
                if batch_idx % check_grad_every == 0:  # åªåœ¨æ£€æŸ¥æ¢¯åº¦çš„batchæ˜¾ç¤ºæ­£å¸¸ä¿¡æ¯
                    print(f"âœ… [Epoch {epoch}, Batch {batch_idx}] æ¢¯åº¦èŒƒæ•°æ­£å¸¸: {grad_norm:.6f}, æ— éœ€è£å‰ª")

            optimizer.step()

        # è®¡ç®—PSNRå’ŒSSIM
        with torch.no_grad():
            psnr_value = calculate_psnr(enhanced_images, targets)
            ssim_value = calculate_ssim(enhanced_images, targets)

        total_loss += loss.item()
        total_reconstruction_loss += reconstruction_loss.item()
        total_psnr += psnr_value
        total_ssim += ssim_value

        progress_bar.set_postfix(
            loss=loss.item(),
            recon_loss=reconstruction_loss.item(),
            psnr=psnr_value,
            ssim=ssim_value
        )

        del inputs, targets, enhanced_images, loss, reconstruction_loss
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    avg_loss = total_loss / len(train_loader)
    avg_recon_loss = total_reconstruction_loss / len(train_loader)
    avg_psnr = total_psnr / len(train_loader)
    avg_ssim = total_ssim / len(train_loader)

    return avg_loss, avg_recon_loss, avg_psnr, avg_ssim


def validate(model, val_loader, device, use_amp=False):
    """
    åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹
    """
    model.eval()
    total_val_loss = 0
    total_val_recon_loss = 0
    total_val_psnr = 0
    total_val_ssim = 0

    batch_count = 0
    with torch.no_grad():
        for batch_data in val_loader:
            inputs = batch_data['input'].to(device, non_blocking=True)
            targets = batch_data['target'].to(device, non_blocking=True)

            # ä½¿ç”¨æ··åˆç²¾åº¦è®¡ç®—
            if use_amp:
                if USE_NEW_AMP:
                    with autocast('cuda'):
                        enhanced_images = model(inputs)  # éªŒè¯æ¨¡å¼åªè¿”å›enhanced_images
                else:
                    with autocast():
                        enhanced_images = model(inputs)  # éªŒè¯æ¨¡å¼åªè¿”å›enhanced_images
            else:
                enhanced_images = model(inputs)  # éªŒè¯æ¨¡å¼åªè¿”å›enhanced_images

            # æ‰‹åŠ¨è®¡ç®—æŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
            l1_loss = L1ReconstructionLoss()
            reconstruction_loss = l1_loss(enhanced_images, targets)
            loss = reconstruction_loss  # éªŒè¯æ—¶ä¸éœ€è¦è¾…åŠ©æŸå¤±

            # è®¡ç®—PSNRå’ŒSSIM
            psnr_value = calculate_psnr(enhanced_images, targets)
            ssim_value = calculate_ssim(enhanced_images, targets)

            total_val_loss += loss.item()
            total_val_recon_loss += reconstruction_loss.item()
            total_val_psnr += psnr_value
            total_val_ssim += ssim_value
            batch_count += 1

            del inputs, targets, enhanced_images, loss, reconstruction_loss
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    avg_val_loss = total_val_loss / batch_count
    avg_val_recon_loss = total_val_recon_loss / batch_count
    avg_val_psnr = total_val_psnr / batch_count
    avg_val_ssim = total_val_ssim / batch_count

    return avg_val_loss, avg_val_recon_loss, avg_val_psnr, avg_val_ssim


def main(args):
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
    use_amp = args.use_amp and torch.cuda.is_available() and AMP_AVAILABLE
    if use_amp:
        print(f"å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP) - ä½¿ç”¨{'æ–°' if USE_NEW_AMP else 'æ—§'}ç‰ˆæœ¬API")
        scaler = GradScaler()
    else:
        scaler = None
        if args.use_amp and not AMP_AVAILABLE:
            print("è­¦å‘Šï¼šè¯·æ±‚å¯ç”¨AMPä½†ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ™®é€šç²¾åº¦è®­ç»ƒ")

    # è®¾ç½®CUDAæ€§èƒ½ä¼˜åŒ– - é»˜è®¤ä½¿ç”¨ç¡®å®šæ€§è®¾ç½®ä»¥ä¸Optunaä¸€è‡´
    if torch.cuda.is_available():
        # ä½¿ç”¨ç¡®å®šæ€§CUDNNè®¾ç½®ï¼ˆä¸Optunaä¼˜åŒ–ä¸€è‡´ï¼‰
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed(args.seed)
        np.random.seed(args.seed)
        print("ğŸ”’ ä½¿ç”¨ç¡®å®šæ€§CUDNNè®¾ç½®ï¼ˆä¸Optunaä¼˜åŒ–ä¸€è‡´ï¼‰")

    # åˆ›å»ºç»“æœå’Œæ£€æŸ¥ç‚¹ç›®å½•
    save_dir = args.save_dir
    os.makedirs(save_dir, exist_ok=True)

    # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
    root_dir = os.path.expanduser(args.data_dir)
    train_loader, val_loader, _ = get_data_loaders(
        root_dir=root_dir,
        batch_size=args.batch_size,
        eval_batch_size=16,
        num_workers=args.num_workers
    )

    print(f"è®­ç»ƒé›†batchæ•°é‡: {len(train_loader)}")
    print(f"éªŒè¯é›†batchæ•°é‡: {len(val_loader)}")

    # åˆå§‹åŒ–æ¨¡å‹
    model = Model().to(device)

    # ä½¿ç”¨torch.compileä¼˜åŒ–æ¨¡å‹ï¼ˆå¦‚æœPyTorchç‰ˆæœ¬>=2.0ï¼‰
    if args.compile and hasattr(torch, 'compile'):
        print("ä½¿ç”¨torch.compileä¼˜åŒ–æ¨¡å‹")
        model = torch.compile(model)

    # æ£€æŸ¥æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤
    start_epoch = 1
    if args.resume:
        if os.path.isfile(args.resume):
            print(f"ä» {args.resume} åŠ è½½æ£€æŸ¥ç‚¹")
            checkpoint = torch.load(args.resume, map_location=device)
            model.load_state_dict(checkpoint['model_state_dict'])
            start_epoch = checkpoint['epoch'] + 1
            print(f"ä»ç¬¬ {start_epoch} è½®æ¢å¤è®­ç»ƒ")
        else:
            print(f"åœ¨ {args.resume} æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹")

    # åˆå§‹åŒ–AdamWä¼˜åŒ–å™¨
    optimizer = optim.AdamW(
        model.parameters(),
        lr=args.lr,
        weight_decay=args.weight_decay,
        betas=(0.9, 0.999),
        eps=1e-8
    )

    print(f"ä½¿ç”¨AdamWä¼˜åŒ–å™¨: åˆå§‹å­¦ä¹ ç‡={args.lr}, æƒé‡è¡°å‡={args.weight_decay}")

    # æ‰“å°å­¦ä¹ ç‡è°ƒåº¦ä¿¡æ¯
    print(f"å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥: Warmup({args.warmup_epochs}è½®) + ä½™å¼¦é€€ç«")
    print(f"  - é™¡å³­åº¦å‚æ•°: {args.steepness}")
    print(f"  - åŠ é€Ÿå› å­: {args.acceleration_factor}")
    print(f"  - æœ€å°å­¦ä¹ ç‡: {args.lr * args.min_lr_factor:.2e}")

    # å¦‚æœæ¢å¤è®­ç»ƒï¼Œä¹ŸåŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
    if args.resume and os.path.isfile(args.resume):
        try:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            print("åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€")
        except:
            print("ä¼˜åŒ–å™¨çŠ¶æ€åŠ è½½å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç”±äºä¼˜åŒ–å™¨ç±»å‹å˜æ›´ï¼Œå°†ä½¿ç”¨æ–°çš„ä¼˜åŒ–å™¨çŠ¶æ€")

        # å¦‚æœä½¿ç”¨æ··åˆç²¾åº¦ï¼Œæ¢å¤scalerçŠ¶æ€
        if use_amp and 'scaler_state_dict' in checkpoint:
            scaler.load_state_dict(checkpoint['scaler_state_dict'])
            print("åŠ è½½æ··åˆç²¾åº¦ç¼©æ”¾å™¨çŠ¶æ€")

    # è®­ç»ƒæ—¥å¿—è®¾ç½®
    log_file = os.path.join(save_dir, 'training_log.txt')
    if start_epoch == 1:
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write(f"è®­ç»ƒå¼€å§‹äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å‚æ•°: {args}\n")
            f.write(f"ä¼˜åŒ–å™¨: AdamW, åˆå§‹å­¦ä¹ ç‡={args.lr}, æƒé‡è¡°å‡={args.weight_decay}\n")
            f.write(f"å­¦ä¹ ç‡è°ƒåº¦: Warmup({args.warmup_epochs}è½®) + ä½™å¼¦é€€ç« (é™¡å³­åº¦={args.steepness}, åŠ é€Ÿ={args.acceleration_factor}, æœ€å°lr={args.lr*args.min_lr_factor:.2e})\n")
            f.write(f"æ¨¡å‹ä¿å­˜ç­–ç•¥: ä»…ä¿å­˜éªŒè¯PSNRæœ€é«˜çš„æ¨¡å‹\n")
            f.write(f"æ—©åœç­–ç•¥: åŸºäºéªŒè¯PSNRåœæ­¢æ”¹å–„è¿›è¡Œæ—©åœ\n")
            f.write(f"æ¢¯åº¦æ£€æŸ¥é¢‘ç‡: æ¯{args.check_grad_every}ä¸ªbatchæ£€æŸ¥ä¸€æ¬¡\n\n")
            f.write(
                "è½®æ¬¡,è®­ç»ƒæŸå¤±,è®­ç»ƒé‡å»ºæŸå¤±,è®­ç»ƒPSNR,è®­ç»ƒSSIM,éªŒè¯æŸå¤±,éªŒè¯é‡å»ºæŸå¤±,éªŒè¯PSNR,éªŒè¯SSIM,å­¦ä¹ ç‡,ç”¨æ—¶(ç§’)\n")

    # ä¿®æ”¹ï¼šä½¿ç”¨éªŒè¯PSNRä½œä¸ºæœ€ä½³æ¨¡å‹åˆ¤æ–­æ ‡å‡†
    best_val_psnr = 0.0  # åˆå§‹åŒ–ä¸º0ï¼Œå› ä¸ºPSNRè¶Šé«˜è¶Šå¥½
    if args.resume and os.path.isfile(args.resume) and 'val_psnr' in checkpoint:
        best_val_psnr = checkpoint['val_psnr']
        print(f"æ¢å¤æœ€ä½³éªŒè¯PSNR: {best_val_psnr:.4f}")

    # æ—©åœç›¸å…³å˜é‡åˆå§‹åŒ– - ä¿®æ”¹ä¸ºåŸºäºPSNR
    early_stopping_counter = 0
    early_stopping_max_val_psnr = 0.0  # è®°å½•æœ€é«˜çš„éªŒè¯PSNR

    # å¼€å§‹è®­ç»ƒå¾ªç¯
    print(f"\nå¼€å§‹è®­ç»ƒï¼Œå…±{args.epochs}è½®...")
    print(f"æ¨¡å‹ä¿å­˜ç­–ç•¥: ä»…ä¿å­˜éªŒè¯PSNRæœ€é«˜çš„æ¨¡å‹")
    print(f"æ—©åœç­–ç•¥: åŸºäºéªŒè¯PSNRåœæ­¢æ”¹å–„è¿›è¡Œæ—©åœ (è€å¿ƒå€¼: {args.patience}, æœ€å°æ”¹å–„: {args.min_delta})")
    print(f"ğŸ” æ¢¯åº¦æ£€æŸ¥: æ¯{args.check_grad_every}ä¸ªbatchæ£€æŸ¥ä¸€æ¬¡æ¢¯åº¦çŠ¶æ€")

    for epoch in range(start_epoch, args.epochs + 1):
        start_time = time.time()
        # model.color_transform.capture_epoch(epoch)  # æ–°ç‰ˆæœ¬ä¸éœ€è¦epochä¿¡æ¯

        # åº”ç”¨warmup + ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦
        warmup_cosine_schedule(optimizer, epoch, args.warmup_epochs, args.epochs,
                              args.min_lr_factor, args.steepness, args.acceleration_factor)
        current_lr = optimizer.param_groups[0]['lr']

        # è®­ç»ƒä¸€ä¸ªepochï¼ˆæ·»åŠ æ¢¯åº¦æ£€æŸ¥ï¼‰
        train_loss, train_recon_loss, train_psnr, train_ssim = train_one_epoch(
            model, train_loader, optimizer, device, epoch, scaler, use_amp, args.check_grad_every
        )

        # éªŒè¯
        val_loss, val_recon_loss, val_psnr, val_ssim = validate(model, val_loader, device, use_amp)

        # è®¡ç®—ç”¨æ—¶
        epoch_time = time.time() - start_time

        # æ‰“å°ç»“æœ
        print(f"è½®æ¬¡ {epoch}/{args.epochs} - "
              f"è®­ç»ƒæŸå¤±: {train_loss:.4f}, "
              f"è®­ç»ƒé‡å»ºæŸå¤±: {train_recon_loss:.4f}, "
              f"è®­ç»ƒPSNR: {train_psnr:.2f}, "
              f"è®­ç»ƒSSIM: {train_ssim:.4f}, "
              f"éªŒè¯æŸå¤±: {val_loss:.4f}, "
              f"éªŒè¯é‡å»ºæŸå¤±: {val_recon_loss:.4f}, "
              f"éªŒè¯PSNR: {val_psnr:.2f}, "
              f"éªŒè¯SSIM: {val_ssim:.4f}, "
              f"å­¦ä¹ ç‡: {current_lr:.6f}, "
              f"ç”¨æ—¶: {epoch_time:.2f}ç§’")

        # è®°å½•æ—¥å¿—
        with open(log_file, 'a') as f:
            f.write(
                f"{epoch},{train_loss:.6f},{train_recon_loss:.6f},{train_psnr:.4f},{train_ssim:.6f},"
                f"{val_loss:.6f},{val_recon_loss:.6f},{val_psnr:.4f},{val_ssim:.6f},"
                f"{current_lr:.6f},{epoch_time:.2f}\n")

        # ä¿®æ”¹ï¼šåŸºäºéªŒè¯PSNRä¿å­˜æœ€ä½³æ¨¡å‹
        if val_psnr > best_val_psnr:
            best_val_psnr = val_psnr
            checkpoint_path = os.path.join(save_dir, 'best_model.pth')

            save_dict = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
                'val_recon_loss': val_recon_loss,
                'val_psnr': val_psnr,
                'val_ssim': val_ssim,
                'train_loss': train_loss,
                'train_recon_loss': train_recon_loss,
                'train_psnr': train_psnr,
                'train_ssim': train_ssim,
                'lr': current_lr
            }

            if use_amp:
                save_dict['scaler_state_dict'] = scaler.state_dict()

            torch.save(save_dict, checkpoint_path)
            print(f"â˜… éªŒè¯PSNRåˆ›æ–°é«˜ï¼ä¿å­˜æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹åˆ° {checkpoint_path} (PSNR: {val_psnr:.4f})")

            weights_path = os.path.join(save_dir, 'best_model_weights.pth')
            torch.save(model.state_dict(), weights_path)
            print(f"â˜… ä¿å­˜æœ€ä½³æ¨¡å‹æƒé‡åˆ° {weights_path}")


        # ä¿®æ”¹ï¼šåŸºäºéªŒè¯PSNRçš„æ—©åœé€»è¾‘
        if val_psnr > early_stopping_max_val_psnr + args.min_delta:
            early_stopping_max_val_psnr = val_psnr
            early_stopping_counter = 0
            print(f"éªŒè¯PSNRæ˜¾è‘—æå‡ã€‚æ—©åœè®¡æ•°å™¨é‡ç½®ã€‚")
        else:
            early_stopping_counter += 1
            print(f"éªŒè¯PSNRæœªæ˜¾è‘—æå‡ã€‚æ—©åœè®¡æ•°å™¨: {early_stopping_counter}/{args.patience}")

            if early_stopping_counter >= args.patience:
                print(f"æ—©åœåœ¨ç¬¬{epoch}è½®è®­ç»ƒåè§¦å‘ï¼æœ€ä½³éªŒè¯PSNR: {best_val_psnr:.4f}")
                break

    # è®­ç»ƒå®Œæˆ
    print(f"è®­ç»ƒå®Œæˆã€‚æœ€ä½³éªŒè¯PSNR: {best_val_psnr:.4f}")
    print(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {save_dir}/best_model.pth")
    print(f"æœ€ä½³æƒé‡å·²ä¿å­˜åˆ°: {save_dir}/best_model_weights.pth")

    # æ•°æ®é›†è·¯å¾„é€‰æ‹©:
    # LOLv1: ./datasets/LOL_V1/lol_dataset
    # LOLv2: ./datasets/LOL-v2
    # LSRW:  ./datasets/OpenDataLab___LSRW/raw/LSRW
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è®­ç»ƒä½å…‰ç…§å›¾åƒå¢å¼ºæ¨¡å‹")
    parser.add_argument('--data_dir', type=str,
                        default="../swin-MOA/LOL-v2-Dataset/archive/LOL-v2/Real_captured",
                        help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--batch_size', type=int, default=4, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--epochs', type=int, default=1200, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=1e-4, help='åˆå§‹å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-2, help='æƒé‡è¡°å‡')
    parser.add_argument('--save_dir', type=str, default='./checkpoints', help='ä¿å­˜æ¨¡å‹çš„ç›®å½•')
    parser.add_argument('--num_workers', type=int, default=20, help='æ•°æ®åŠ è½½å™¨çš„å·¥ä½œçº¿ç¨‹æ•°')
    parser.add_argument('--resume', type=str, default=None, help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    # æ—©åœç›¸å…³å‚æ•°
    parser.add_argument('--patience', type=int, default=2000, help='æ—©åœè€å¿ƒå€¼')
    parser.add_argument('--min_delta', type=float, default=1e-5, help='æ—©åœæœ€å°æ”¹å–„é˜ˆå€¼')
    # GPUä¼˜åŒ–ç›¸å…³å‚æ•°
    parser.add_argument('--use_amp', action='store_true', help='æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ')
    # ç§»é™¤deterministicå‚æ•°ï¼Œç°åœ¨é»˜è®¤ä½¿ç”¨ç¡®å®šæ€§è®¾ç½®ä»¥ä¸Optunaä¸€è‡´
    # parser.add_argument('--deterministic', action='store_true', help='æ˜¯å¦ä½¿ç”¨ç¡®å®šæ€§ç®—æ³•')
    parser.add_argument('--seed', type=int, default=3407, help='éšæœºç§å­')
    parser.add_argument('--compile', action='store_true', help='ä½¿ç”¨torch.compileä¼˜åŒ–æ¨¡å‹')
    # å­¦ä¹ ç‡è°ƒåº¦ç›¸å…³å‚æ•°ï¼ˆé»˜è®¤å¼€å¯warmup+ä½™å¼¦é€€ç«ï¼‰
    parser.add_argument('--warmup_epochs', type=int, default=10, help='Warmupçš„è½®æ•°ï¼ˆé»˜è®¤10ï¼‰')
    parser.add_argument('--min_lr_factor', type=float, default=0.001, help='æœ€å°å­¦ä¹ ç‡å€æ•°')
    parser.add_argument('--steepness', type=float, default=10, help='ä½™å¼¦é€€ç«é™¡å³­åº¦å‚æ•°')
    parser.add_argument('--acceleration_factor', type=float, default=3.0, help='å­¦ä¹ ç‡è¡°å‡åŠ é€Ÿå› å­')
    # æ¢¯åº¦æ£€æŸ¥ç›¸å…³å‚æ•°
    parser.add_argument('--check_grad_every', type=int, default=1, help='æ¯Nä¸ªbatchæ£€æŸ¥ä¸€æ¬¡æ¢¯åº¦')
    
    # Optunaè¶…å‚æ•°ä¼˜åŒ–ç›¸å…³å‚æ•°
    parser.add_argument('--optuna', action='store_true', help='å¯ç”¨Optunaè¶…å‚æ•°ä¼˜åŒ–')
    parser.add_argument('--optuna_trials', type=int, default=30, help='Optunaè¯•éªŒæ¬¡æ•° (å®˜æ–¹å»ºè®®20-50)')
    parser.add_argument('--optuna_epochs', type=int, default=8, help='æ¯ä¸ªè¯•éªŒçš„è®­ç»ƒè½®æ•° (å®˜æ–¹å»ºè®®8-10)')
    parser.add_argument('--optuna_study_name', type=str, default='mase_net_optimization', help='Optunaç ”ç©¶åç§°')
    parser.add_argument('--optuna_storage', type=str, default='sqlite:///optuna_studies/mase_net_full_2_study.db', help='Optunaå­˜å‚¨æ•°æ®åº“è·¯å¾„')
    parser.add_argument('--diagnostic', action='store_true', help='è¿è¡Œè¯Šæ–­æµ‹è¯•')

    args = parser.parse_args()
    
    if args.diagnostic:
        success = run_diagnostic_test()
        if success:
            print("ğŸ‰ è¯Šæ–­æµ‹è¯•é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹æ­£å¼ä¼˜åŒ–")
        else:
            print("âŒ è¯Šæ–­æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ä¿®æ”¹")
    elif args.optuna:
        run_optuna_optimization(args)
    else:
        main(args)
